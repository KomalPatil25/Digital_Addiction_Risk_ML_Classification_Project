# Digital_Addiction_Risk_ML_Classification_Project

# ğŸ“± Digital Addiction Risk Prediction (Random Forest ML Project) <br>
ğŸ“Œ Project Overview <br>

This machine learning project predicts the risk level of digital addiction among individuals based on behavioral and usage-related features.<br>
The model uses a Random Forest Classifier to classify whether a person has a high or low risk of digital addiction.<br>

The goal of this project is to demonstrate a complete ML workflow: <br>
â–«ï¸ Data preprocessing <br>
â–«ï¸ Exploratory Data Analysis (EDA) <br>
â–«ï¸ missing values <br>
â–«ï¸ imbalance handling (SMOTE) <br>
â–«ï¸ training & evaluation <br>
â–«ï¸ analysis <br>

# ğŸ“Š Dataset <br>
File: digital_addiction_risk.csv <br>

The dataset contains behavioral and digital usage features such as: <br>
â–«ï¸ Screen time <br>
â–«ï¸ Social media usage <br>
â–«ï¸ Sleep patterns <br>
â–«ï¸ Device usage habits <br>
â–«ï¸ Demographic or lifestyle indicators <br>

# Target Variable:<br>
Digital_Addiction_Risk (classification label) <br>

# âš™ï¸ Technologies Used <br>
â–«ï¸ Python ğŸ <br>
â–«ï¸ Pandas & NumPy (data processing) <br>
â–«ï¸ Seaborn & Matplotlib (EDA & visualization) <br>
â–«ï¸ Scikit-learn (ML modeling) <br>
â–«ï¸ Imbalanced-learn (SMOTE for class balancing) <br>

# ğŸ” Machine Learning Workflow <br>
1ï¸âƒ£ Data Preprocessing <br>
â–«ï¸ Loaded dataset using Pandas <br>
â–«ï¸ Checked dataset shape & structure <br>
â–«ï¸ Identified missing values <br>
â–«ï¸ Handled null values <br>
â–«ï¸ Encoded categorical features <br>

2ï¸âƒ£ Exploratory Data Analysis (EDA)  <br>
â–«ï¸ Distribution analysis <br>
â–«ï¸ Feature relationships <br>
â–«ï¸ Correlation insights <br>
â–«ï¸ Class distribution check <br>

3ï¸âƒ£ Handling Class Imbalance <br>
â–«ï¸ The dataset had imbalanced classes, so: <br>
â–«ï¸ Applied SMOTE (Synthetic Minority Oversampling Technique) <br>
â–«ï¸ Balanced minority and majority classes <br>

4ï¸âƒ£ Model Training <br>
Algorithm used: <br>

ğŸ‘‰ Random Forest Classifier  <br>
Reason: <br>
â–«ï¸ Handles nonlinear relationships <br>
â–«ï¸ Robust to noise <br>
â–«ï¸ Works well with tabular behavioral data <br>

Train-test split: <br>
â–«ï¸ 70% Training <br>
â–«ï¸ 30% Testing <br>

ğŸ“ˆ Model Evaluation <br>
Metrics used: <br>
â–«ï¸ Accuracy Score <br>
â–«ï¸ Classification Report <br>
â–«ï¸ Confusion Matrix <br>

Results: <br>
â–«ï¸ High training accuracy <br>
â–«ï¸ Good generalization on test data <br>
â–«ï¸ Balanced precision & recall across classes <br>

ğŸ“Š Evaluation Output Example <br>
Training Accuracy: XX% <br>
Testing Accuracy: XX% <br>

Classification Report: <br>
precision    recall    f1-score <br>
...

# ğŸ¯ Key Learnings <br>
â–«ï¸ Real-world ML pipeline implementation <br>
â–«ï¸ Handling imbalanced datasets with SMOTE <br>
â–«ï¸ Random Forest classification <br>
â–«ï¸ EDA & feature understanding <br>
â–«ï¸ Model evaluation techniques <br>

# ğŸ“¬ Author <br>

# Komal Patil <br>
Aspiring Data Scientist | Machine Learning Enthusiast <br>
